{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "from googletrans import Translator\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import requests\n",
    "import datetime\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ko_noun_dict.pkl', \"rb\") as f:\n",
    "    ko_dict = pickle.load(f)\n",
    "    \n",
    "with open('./data/en_noun_dict.pkl', \"rb\") as f:\n",
    "    en_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_data(ko_dict, en_dict):\n",
    "    for i in range(len(ko_dict)):\n",
    "        ko_vector = list(ko_dict.values())[i]\n",
    "        en_vector = list(en_dict.values())[i]\n",
    "        \n",
    "#         yield (ko_word, ko_vector, en_word, en_vector)\n",
    "        yield (ko_vector, en_vector)\n",
    "    \n",
    "def get_noun_data_2(ko_vec, en_vec):\n",
    "    for i in range(len(ko_vec)):\n",
    "        ko_vector = ko_vec[i]\n",
    "        en_vector = en_vec[i]\n",
    "        \n",
    "        yield ko_vector, en_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(get_noun_data_2, \n",
    "                              (tf.float64, tf.float64),\n",
    "                              (tf.TensorShape([300]), tf.TensorShape([300])),\n",
    "                               args=(list(ko_dict.values()), list(en_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.transformer import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_enc = Encoder(num_layers=1, d_model=1, num_heads=1, dff=512, input_vocab_size=0, maximum_position_encoding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input shape (64, 300, 1)\n",
      "Scaled_attention Shape :  (64, 1, 300, 1)\n",
      "Scaled_attention Shape :  (64, 300, 1, 1)\n",
      "Concat attention Shape : (64, 300, 1)\n",
      "(64, 300, 1)\n"
     ]
    }
   ],
   "source": [
    "temp_input = tf.random.uniform((64, 300), dtype=tf.float32, minval=0, maxval=1)\n",
    "sample_encoder_output = sample_enc(temp_input, training=False, mask=None)\n",
    "print(sample_encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "d_model = 1\n",
    "dff = 512\n",
    "num_head = 1\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, y_true, y_pred):\n",
    "        e = y_true - y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.Huber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    tic = time.time()\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FlatMapDataset shapes: ((300,), (300,)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
